# -*- coding: utf-8 -*-
"""Copia di Copia di Processing_Test_PPG_Balla.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wZB0apjCldgOYnlMgu6qtaumK2rJNVc1

#1. Set up environment
"""

# Commented out IPython magic to ensure Python compatibility.
# Connecting Google Colab to Google Drive
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive/My Drive/corino/test_students

seed = 42

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['PYTHONHASHSEED'] = str(seed)
os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=Warning)

import numpy as np
np.random.seed(seed)

import logging

import random
random.seed(seed)

# Import tensorflow
import tensorflow as tf
from tensorflow import keras as tfk
from tensorflow.keras import layers as tfkl
tf.autograph.set_verbosity(0)
tf.get_logger().setLevel(logging.ERROR)
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)
tf.random.set_seed(seed)
tf.compat.v1.set_random_seed(seed)
print(tf.__version__)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import matplotlib
import numpy as np
import matplotlib.pyplot as plt
import scipy.io
import os
from sklearn import preprocessing
import pandas as pd
import scipy.signal
import pickle
import csv

!ls

"""#1.1 Data importation

We import the files containing the position of the peaks in the signal, which are the files ending with spk.mat.
"""

# Folder where the files are located
cartella = '/gdrive/My Drive/corino/test_students'

files = [file for file in os.listdir(cartella) if file.endswith('S128_250_spk.mat')]

peaks = []

# Loop through all the spk.mat files and load each file into a matrix.
for file in files:
    # Extract the file name without the extension
    nome_file = os.path.splitext(file)[0]

    # create the full path of the file.
    percorso_file = os.path.abspath(os.path.join(cartella, file))

    # load the file
    matrice = scipy.io.loadmat(percorso_file)

    # Add the matrix to the list with the file name as the key.
    peaks.append({nome_file: matrice})

#Now matrices contains a list of dictionaries, each of which has the file name as the key and the matrix as the value.

"""The same procedure has been done for the other files as well.

We import the files containing the label of the peaks , which are the files ending with ann.mat.

We import the files containing the PPG signals in samples, which are the files ending with 128.mat and 250.mat.
"""

cartella = '/gdrive/My Drive/corino/test_students'

files = [file for file in os.listdir(cartella) if file.endswith(('S128_250.mat'))]

signal = []
for file in files:
    nome_file = os.path.splitext(file)[0]
    percorso_file = os.path.abspath(os.path.join(cartella, file))
    matrice = scipy.io.loadmat(percorso_file)
    signal.append({nome_file: matrice})

"""# 2. Data manipulation and outlier detection

## 2.1 Maintain index correspondences between different lists.

This code cell was created to ensure correspondence between the arrangement of files in different lists so that the i-th file in "peaks" contains the position of peaks of the signal present in the i-th file of "signal," and the same goes for "labels."

To do this, we used the first 8 characters of the file names because they refer to the patient and therefore allow us to associate the peak positions and labels with their respective signals.
"""

# To have the same order among various files
# extract the first 8 characters from the dictionary key's name.
def estrai_codice(dizionario):
    return list(dizionario.keys())[0][:8]

# Sort the lists based on the first 8 characters of the code.
peaks_nuovo= sorted(peaks, key=estrai_codice)
signal_nuovo=sorted(signal, key=estrai_codice)

peaks_nuovo[0]

"""##2.4.Extrapolation of only the meaningful data"""

ppg = [elemento[chiave]['ppg'] for elemento in signal for chiave in elemento]

peak = [elemento[chiave]['speaks'] for elemento in peaks for chiave in elemento]

print(len(ppg),len(peak))

"""# 3.Signal Processing

##3.1. Downsampling from 250Hz signals to 128Hz

The first step in the preprocessing is to downsample the signal with higher sampling frequency, i.e 250 Hz so as to unify all the signals to the same sampling frequency (180 Hz). The selection of downsampling with respect to oversampling is led by the fact that, in the case of downsampling, the number of samples is reduced, inevitably lowering the resolution and, consequently, the quality of the signal. In the case of upsampling, the number of samples is increased, but it doesn't necessarily improve resolution or quality; in fact, the added samples are computed and not actual measurements.

We plot the distribution of signal lengths. We can see that the lengths are around 200000, corresponding to samples with fs=128Hz, and around 400000, corresponding to samples with fs=250 Hz.

We apply downsampling only to the signals with fs=250 Hz and to the respective positions of the peaks
"""

from scipy.signal import resample

def downsample(signal_orig, rpeaks, signal_fs, fs_new=128):
    """ Given the signal and its annotation, downsample the signal and
        modify the positions of the annotations
    """
    fs = signal_fs

    new_num_samples = int(len(signal_orig)/fs*fs_new)
    downsamp_signal = np.array(resample(signal_orig, new_num_samples))

    downsamp_ann = rpeaks/(fs/fs_new)
    downsamp_ann = np.round(downsamp_ann).astype(int)

    return downsamp_signal, downsamp_ann

"""
From the initial data, we have seen that patients with fs=128 Hz go up to 62. So, we apply downsampling from 63 to 91.

So the cicle start from 62 to 91 because the first index is 0 not 1



"""

ppg, peak= downsample(ppg[0], peak[0], signal_fs=250, fs_new=128)

peak

"""Let's plot the distribution of signal lengths after downsampling, and we can observe that now the lengths are all concentrated around 200000.

##3.2. Delete movement artifacts

We noticed that there are very noisy parts in the signals due to movement artifacts. These segments of the signal do not carry any useful information that can be utilized for classification. Therefore, we have decided to remove them.

It is observed that the PPG signal typically oscillates within a limited amplitude range, while movement artefacts exhibit a wide variation in amplitude

So we have defined a function to remove artifacts. To remove artifacts, we consider a sliding window of width 90 samples. If there are more than 5 samples within this window with a height < -2.2 or > 2.2, we set all the samples within the window to 0. So the idea is to have zeros instead of artifacts in the signal.
"""

def rimuovi_artefatti_con_limiti(segnale, soglia_inferiore, soglia_superiore, limite_fuori_soglia):
    lunghezza_finestra = 90

    for i in range(len(segnale) - lunghezza_finestra + 1):
        finestra = segnale[i:i + lunghezza_finestra]  #Through a sliding window, we analyze a portion of the signal at a time.
        conteggio_sopra_soglia = np.sum((finestra > soglia_superiore) | (finestra < soglia_inferiore)) #count the number of samples that overcome the threshold

        if conteggio_sopra_soglia > limite_fuori_soglia:
            segnale[i:i + lunghezza_finestra] = 0   #if more than N samples equal to limite_fuori_soglia are > soglia_superiore or < soglia_inferiore
            # put the signal inside the window equal to 0
    return segnale

#Application of the function to remove the artifact
#ppg_cleaned_final = []
ppg_cleaned_final= rimuovi_artefatti_con_limiti(ppg, soglia_inferiore=-2.2, soglia_superiore=2.2, limite_fuori_soglia=5)

"""
Another check was applied to the signal, removing all samples < -2.2 and > 2.5 to ensure the removal of all artifacts."""

def rimuovi_punti_fuori_soglia(segnale, soglia_inferiore=-2.2, soglia_superiore=2.5):
    segnale[(segnale > soglia_superiore) | (segnale < soglia_inferiore)] = 0 #if the sample overcome the threshold put it equal to 0
    return segnale

#Application of the function
#ppg_cleaned_final1 = []
ppg_cleaned_final1=rimuovi_punti_fuori_soglia(ppg_cleaned_final, soglia_inferiore=-2.2, soglia_superiore=2.5)

ppg_cleaned_final1[0]

"""plot the raw signal and the signal without artifacts to show the difference.

## 3.3. Band Pass Filter

The final step in the preprocessing involves filtering the signal to retain only the frequency range between 0.5 and 5 Hz. For this purpose, a second-order Chebyshev filter is employed, which, in our case, outperforms a Butterworth filter. The filtering process aims to achieve a smoother shape for the PPG peaks, effectively reducing noise. By employing a band-pass filter, noise related to potential signal drift is addressed, while also eliminating high-frequency noise. This filtering step is instrumental in enhancing the overall quality of the PPG signal, ensuring a more accurate representation for subsequent analysis.
"""

from scipy.signal import butter, lfilter
from scipy import stats

from scipy.integrate import quad
import numpy as np

"""This commented code represent the implemented Butterworth filter but are not used for the reasons indicated."""

import scipy.signal

def filter_signal(signal, fs):
    N = 4
    Range = [0.5, 5]  #range of frequency
    Wn = [r/(fs/2) for r in Range]

    # Specify Chebyshev Type I filter parameters
    rp = 40 # passband ripple in dB
    b, a = scipy.signal.cheby2(N, rp, Wn, 'bandpass', analog=False)

    output_signal = scipy.signal.filtfilt(b, a, signal)
    return output_signal

ppg_cleaned_final1= ppg_cleaned_final1.flatten()
processed_signals=filter_signal(ppg_cleaned_final1, fs=128)

"""Plot the signal without artifacts before and after the filter to show the differences.

# 4 Segmentation and removing of artifacts

To isolate the peaks, we used the function segmenta_picco_ppg.
The initial idea is to create segments that include the peak, starting from the left minimum to the right minimum, to use them for classification. Thus, each segment ultimately comprises a peak, which will then be classified by our models.

To build the segments, the findpeaks function was used on the signal flipped so that it finds not the peaks but the minima surrounding the peaks.

To find the minima, we use the information of the peak positions that we already know. For each peak position, we apply the findpeaks function to the flipped signal to find the left minima by applying it from the origin of the signal up to the peak position, and similarly, to find the right minima, we apply it from the peak position to the end of the signal.

The first step taken in this function is to set the indices of the peaks < 0.1 equal to 0 to eliminate them later. This is because the filter applied in the zero-padding parts, where there were previously artifacts, caused very small amplitude ripples that are not useful for classification, as they represent artifacts.

Once the findpeaks function is applied and all the left and right minima of each peak are found, we take from each peak the last left minimum found and the first right minimum found, as those immediately follow the peak
"""

import numpy as np
from scipy.signal import find_peaks
def segmenta_picco_ppg(ppg_signal, index_picco):
  sinistra= []
  destra= []
  indici_artefatti=[]
  minimo_destra=0
  minimo_sinistra=0


  sinistra, _ = find_peaks(-ppg_signal[:index_picco]) #we apply the findpeaks function from the origin of the signal up to the peak to find the left minima

  destra, _ = find_peaks(-ppg_signal[index_picco:])#we apply the findpeaks function from the index peak to the end of the signal to find the right minima
  destra += index_picco
  #We add the index of the maximum to obtain the correct index.
  #This is necessary to shift the indices found on the right side so that they are relative to the actual position in the complete signal and not relative to the position of the peaks


  if sinistra.size > 0 and destra.size > 0:
      minimo_sinistra = sinistra[-1] #I take the last element of the left minima of the peak because it is the closest minimum to the current peak.
      minimo_destra = destra[0] #I take the first element of the right minima of the peak because it is the closest right minimum to the current peak
      #Procedure for the extremes
  elif sinistra.size == 0 and destra.size > 0: #If we are at the beginning of the signal and the minimum is not found.
      minimo_sinistra = 1 #I set the left minimum to 1 instead of 0 so that it is not eliminated later on.
      minimo_destra = destra[0] #not change
  elif destra.size == 0 and sinistra.size > 0: #If we are at the end of the signal and the maximum is not found.
      minimo_destra = len(ppg_signal-1)
      minimo_sinistra = sinistra[-1] #not change

  return minimo_sinistra, minimo_destra
 #index picco will be modified to contain 0 for the indices of signals <0.1.

"""we apply the function for each segment."""

minimi_sinistra_segnale = []
minimi_destra_segnale = []
for i in range(len(peak)):
  min_sinistra, min_destra = segmenta_picco_ppg(processed_signals, peak[i][0])
  minimi_sinistra_segnale.append(min_sinistra)
  minimi_destra_segnale.append(min_destra)

"""# Segmentation"""

def segmenta_picco_ppg(ppg_signal, min_sin, min_destr):
    """
    Segments the PPG signal around the peak.

    Parameters:
    - ppg_signal: The PPG signal
    - index_picco: the index of the peak
    - intervallo_temporale: The desired interval length around the peak (in samples).

    Return:
    - segmento: The segment of the PPG signal around the peak.
    """

    segmento = ppg_signal[min_sin:min_destr] #we take the segment from the left minimum to the right minimum.

    return segmento

""" Application of  the segmentation function."""

segmenti_totali = []
for j in range(len(peak)):
  segmenti_totali.append(segmenta_picco_ppg(processed_signals,minimi_sinistra_segnale[j],minimi_destra_segnale[j]))

"""#5. Save and Load Data"""

save_directory = '/gdrive/MyDrive/corino/Processing_test'
# Change the current working directory
os.chdir(save_directory)

with open('segmenti_128_test.txt', 'wb') as data_file:
  pickle.dump(segmenti_totali, data_file)